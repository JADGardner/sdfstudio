{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python (Singularity SDFStudio) is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/data-NeRF-OSR-Data/RENI-NeuS/2023-03-23_093506//sdfstudio_models/step-000040000.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutputs/data-NeRF-OSR-Data/RENI-NeuS/2023-03-23_093506/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     48\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m40000\u001b[39m\n\u001b[0;32m---> 50\u001b[0m ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(ckpt_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/sdfstudio_models\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/step-\u001b[39;49m\u001b[39m{\u001b[39;49;00mstep\u001b[39m:\u001b[39;49;00m\u001b[39m09d\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m, map_location\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     51\u001b[0m model_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m ckpt[\u001b[39m'\u001b[39m\u001b[39mpipeline\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/home/user/.local/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/home/user/.local/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/home/user/.local/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/data-NeRF-OSR-Data/RENI-NeuS/2023-03-23_093506//sdfstudio_models/step-000040000.ckpt'"
     ]
    }
   ],
   "source": [
    "# set the cwd to the root of the repo\n",
    "import os\n",
    "os.chdir(\"/users/jadg502/scratch/code/sdfstudio/\")\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nerfstudio.configs import base_config as cfg\n",
    "from nerfstudio.configs.method_configs import method_configs\n",
    "from nerfstudio.data.dataparsers.nerfosr_dataparser import NeRFOSR, NeRFOSRDataParserConfig\n",
    "from nerfstudio.models.reni_neus import RENINeuSModel, RENINeuSModelConfig\n",
    "from nerfstudio.pipelines.base_pipeline import VanillaDataManager\n",
    "from nerfstudio.field_components.field_heads import FieldHeadNames\n",
    "from nerfstudio.fields.reni_field import get_directions\n",
    "from nerfstudio.cameras.rays import RayBundle\n",
    "\n",
    "def make_ray_bundle_copy(ray_bundle):\n",
    "    new_ray_bundle = RayBundle(\n",
    "      origins=ray_bundle.origins.detach().clone(),\n",
    "      directions=ray_bundle.directions.detach().clone(),\n",
    "      pixel_area=ray_bundle.pixel_area.detach().clone(),\n",
    "      directions_norm=ray_bundle.directions_norm.detach().clone(),\n",
    "      camera_indices=ray_bundle.camera_indices.detach().clone(),\n",
    "      nears=ray_bundle.nears.detach().clone() if ray_bundle.nears is not None else None,\n",
    "      fars=ray_bundle.fars.detach().clone() if ray_bundle.fars is not None else None,\n",
    "    )\n",
    "    return new_ray_bundle\n",
    "\n",
    "def make_batch_clone(batch):\n",
    "    new_batch = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            new_batch[key] = value.detach().clone()\n",
    "        else:\n",
    "            new_batch[key] = value\n",
    "    return new_batch       \n",
    "\n",
    "# setup config\n",
    "test_mode = 'val'\n",
    "world_size = 1\n",
    "local_rank = 0\n",
    "device = 'cuda:0'\n",
    "\n",
    "ckpt_path = 'outputs/data-NeRF-OSR-Data/RENI-NeuS/2023-03-23_093506/'\n",
    "step = 40000\n",
    "\n",
    "ckpt = torch.load(ckpt_path + '/sdfstudio_models' + f'/step-{step:09d}.ckpt', map_location=device)\n",
    "model_dict = {}\n",
    "for key in ckpt['pipeline'].keys():\n",
    "    if key.startswith('_model.'):\n",
    "        model_dict[key[7:]] = ckpt['pipeline'][key]\n",
    "\n",
    "# load yaml checkpoint config\n",
    "config_path = Path(ckpt_path) / 'config.yml'\n",
    "config = yaml.load(config_path.open(), Loader=yaml.Loader)\n",
    "\n",
    "pipeline_config = config.pipeline\n",
    "pipeline_config.datamanager.dataparser.scene = 'lk2'\n",
    "pipeline_config.datamanager.dataparser.use_session_data = False\n",
    "\n",
    "# if illumination_sampler_random_rotation not in pipeline.config.model add it and set to false\n",
    "try:\n",
    "    pipeline_config.model.illumination_sampler_random_rotation\n",
    "except AttributeError:\n",
    "    pipeline_config.model.illumination_sampler_random_rotation = True\n",
    "try:\n",
    "    pipeline_config.model.illumination_sample_remove_lower_hemisphere\n",
    "except AttributeError:\n",
    "    pipeline_config.model.illumination_sample_remove_lower_hemisphere = True\n",
    "\n",
    "datamanager: VanillaDataManager = pipeline_config.datamanager.setup(\n",
    "    device=device, test_mode=test_mode, world_size=world_size, local_rank=local_rank, \n",
    ")\n",
    "datamanager.to(device)\n",
    "# includes num_eval_data as needed for reni latent code fitting.\n",
    "model = pipeline_config.model.setup(\n",
    "    scene_box=datamanager.train_dataset.scene_box,\n",
    "    num_train_data=len(datamanager.train_dataset),\n",
    "    num_eval_data=len(datamanager.eval_dataset),\n",
    "    metadata=datamanager.train_dataset.metadata,\n",
    "    world_size=world_size,\n",
    "    local_rank=local_rank,\n",
    "    eval_latent_optimisation_source=pipeline_config.eval_latent_optimisation_source,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(model_dict)\n",
    "model.eval()\n",
    "\n",
    "image_idx_original, camera_ray_bundle_original, batch_original = datamanager.next_eval_image(1)\n",
    "\n",
    "True # printing to hide long cell output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Singularity SDFStudio)",
   "language": "python",
   "name": "singularities"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
